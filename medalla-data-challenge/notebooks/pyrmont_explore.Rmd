---
title: "Pyrmont data"
author:
- name: Barnab√© Monnot
  url: https://twitter.com/barnabemonnot
  affiliation: Robust Incentives Group, Ethereum Foundation
  affiliation_url: https://github.com/ethereum/rig
date: "`r Sys.Date()`"
output:
  distill::distill_article:
    toc: yes
    toc_depth: 3
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
description: |
  Onwards!
---

```{r setup, include=FALSE}
library(tidyverse)
library(data.table)
library(patchwork)
library(rmarkdown)
library(ineq)
library(infer)

source(here::here("notebooks/lib.R"))

options(digits=10)
options(scipen = 999) 

# Make the plots a bit less pixellated
knitr::opts_chunk$set(dpi = 300)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

# A minimal theme I like
newtheme <- theme_grey() + theme(
  axis.text = element_text(size = 9),
  axis.title = element_text(size = 12),
  axis.line = element_line(colour = "#000000"),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_blank(),
  legend.title = element_text(size = 12),
  legend.text = element_text(size = 10),
  legend.box.background = element_blank(),
  legend.key = element_blank(),
  strip.text.x = element_text(size = 10),
  strip.background = element_rect(fill = "white")
)
theme_set(newtheme)

myred <- "#F05431"
myyellow <- "#FED152"
mygreen <- "#BFCE80"
client_colours <- c("#000011", "#ff9a02", "#eb4a9b", "#7dc19e")

start_epoch <- 0
end_epoch <- 2240
slots_per_epoch <- 32
until_slot <- (end_epoch + 2) * slots_per_epoch - 1
slot_chunk_res <- until_slot %/% 15
slots_per_year <- 365.25 * 24 * 60 * 60 / 12
epochs_per_year <- slots_per_year / slots_per_epoch
```

```{r eval=FALSE}
# Run this to add to the dataset
start_epoch <- 1931
end_epoch <- 2240

all_bxs <- fread(here::here("pyrmont_data/all_bxs.csv"))
all_ats <- fread(here::here("pyrmont_data/all_ats.csv"))
committees <- fread(here::here("pyrmont_data/committees.csv"))
validators <- fread(here::here("pyrmont_data/initial_validators.csv"))
val_series <- fread(here::here("pyrmont_data/val_series.csv"))
stats_per_slot <- fread(here::here("pyrmont_data/stats_per_slot.csv"))

bxs_and_ats <- start_epoch:end_epoch %>%
  map(get_blocks_and_attestations) %>%
  purrr::transpose() %>%
  map(rbindlist)

new_bxs <- copy(bxs_and_ats$block)
new_bxs[, declared_client := find_client(graffiti)]
list(all_bxs, new_bxs) %>% rbindlist() %>% fwrite(here::here("pyrmont_data/all_bxs.csv"))
rm(new_bxs)

list(all_ats, bxs_and_ats$attestations) %>% rbindlist() %>% fwrite(here::here("pyrmont_data/all_ats.csv"))
rm(bxs_and_ats)

new_committees <- start_epoch:end_epoch %>%
  map(get_committees) %>%
  rbindlist()
list(committees, new_committees) %>% rbindlist() %>% fwrite(here::here("pyrmont_data/committees.csv"))
rm(new_committees)

block_root_at_slot <- get_block_root_at_slot(fread(here::here("pyrmont_data/all_bxs.csv")))
all_ats <- fread(here::here("pyrmont_data/all_ats.csv"))
committees <- fread(here::here("pyrmont_data/committees.csv"))
get_correctness_data(all_ats, block_root_at_slot)

new_val_series <- get_stats_per_val(
  all_ats[att_slot >= (start_epoch-1) * slots_per_epoch & att_slot < end_epoch * slots_per_epoch],
  block_root_at_slot, committees = committees, validators = validators, chunk_size = 10)
list(val_series, new_val_series) %>% rbindlist() %>% fwrite(here::here("pyrmont_data/val_series.csv"))
rm(new_val_series)

new_stats_per_slot <- get_stats_per_slot(
  all_ats[att_slot >= (start_epoch-1) * slots_per_epoch & att_slot < end_epoch * slots_per_epoch],
  committees)
list(stats_per_slot, new_stats_per_slot) %>% rbindlist() %>% fwrite(here::here("pyrmont_data/stats_per_slot.csv"))
rm(new_stats_per_slot)
```

```{r eval=FALSE}
all_bxs <- fread(here::here("pyrmont_data/all_bxs.csv"))
all_ats <- fread(here::here("pyrmont_data/all_ats.csv"))
committees <- fread(here::here("pyrmont_data/committees.csv"))
validators <- fread(here::here("pyrmont_data/initial_validators.csv"))
block_root_at_slot <- get_block_root_at_slot(fread(here::here("pyrmont_data/all_bxs.csv")))
get_correctness_data(all_ats, block_root_at_slot)
stats_per_val <- get_stats_per_val(
  all_ats[att_slot < end_epoch * slots_per_epoch],
  block_root_at_slot, committees = committees, validators = validators, chunk_size = 10)
stats_per_slot <- get_stats_per_slot(
  all_ats[att_slot < end_epoch * slots_per_epoch], committees)

stats_per_val %>% fwrite(here::here("pyrmont_data/val_series.csv"))
stats_per_slot %>% fwrite(here::here("pyrmont_data/stats_per_slot.csv"))
```

```{r eval=FALSE}
(45001:55000) %>%
  map(function(current_slot) {
    if (current_slot %% 1000 == 0) { print(str_c("slot ", current_slot)) }
    get_aggregate_info(all_ats[slot == current_slot])
  }) %>%
  bind_rows() %>%
  group_by(slot) %>%
  summarise(n_subset = sum(n_subset),
            n_subset_ind = sum(n_subset_ind),
            n_strongly_clashing = sum(n_strongly_clashing),
            n_weakly_clashing = sum(n_weakly_clashing)) %>%
  union(read_csv(here::here("pyrmont_data/subset_ats.csv"))) %>%
  write_csv(here::here("pyrmont_data/subset_ats.csv"))
```

```{r cache=TRUE, cache.lazy=FALSE}
all_bxs <- fread(here::here("pyrmont_data/all_bxs.csv"))
all_ats <- fread(here::here("pyrmont_data/all_ats.csv"))
validators <- fread(here::here("pyrmont_data/initial_validators.csv"))
block_root_at_slot <- get_block_root_at_slot(all_bxs)
get_correctness_data(all_ats, block_root_at_slot)
stats_per_slot <- fread(here::here("pyrmont_data/stats_per_slot.csv"))
appearances_in_aggs <- get_appearances_in_agg(all_ats)
myopic_redundant_ats <- get_myopic_redundant_ats(all_ats)
strong_redundant_ats <- get_strong_redundant_ats(all_ats)
subset_ats <- fread(here::here("pyrmont_data/subset_ats.csv"))
```

We look at data between epochs 0 and `r end_epoch` and report updated metrics for the Pyrmont eth2 testnet. You can also find a similar notebook for [Medalla here](https://ethereum.github.io/rig/medalla-data-challenge/notebooks/explore.html).

<aside>
All code available [here](https://github.com/ethereum/rig/blob/master/medalla-data-challenge/notebooks/pyrmont_explore.Rmd).
</aside>

## Performance of duties

### Attester duties

We compare the number of included attestations with the number of expected attestations.

```{r}
stats_per_slot %>%
  .[, slot_chunk:=att_slot %/% slot_chunk_res] %>%
  filter(slot_chunk != max(slot_chunk)) %>%
  group_by(slot_chunk) %>%
  summarise(percent_received = sum(included_ats) / sum(expected_ats) * 100) %>%
  ggplot() +
  geom_line(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_received), colour = myred) +
  geom_point(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_received),
             colour = myred) +
  geom_text(aes(
    x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_received,
    label = round(percent_received, digits = 1)),
    colour = myred, alpha = 0.7, nudge_y = -4) +
  ggtitle("Proportion of included attestations",
          subtitle=str_c("Group size = ", slot_chunk_res, " slots")) +
  xlab("Epoch") +
  ylab("Percent attested and included") +
  ylim(0, 100)
```

### Proposer duties

How many blocks are there in the canonical chain?

```{r}
tibble(slot = 0:until_slot) %>%
  left_join(all_bxs %>%
              select(slot) %>%
              mutate(proposed = 1),
            by = c("slot" = "slot")) %>%
  replace_na(list(proposed = 0)) %>%
  mutate(slot_chunk = slot %/% slot_chunk_res) %>%
  filter(slot_chunk != max(slot_chunk)) %>%
  group_by(slot_chunk) %>%
  summarise(percent_proposed = sum(proposed) / n() * 100) %>%
  ggplot() +
  geom_line(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_proposed), colour = myred) +
  geom_point(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_proposed),
             colour = myred) +
  geom_text(aes(
    x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_proposed,
    label = round(percent_proposed, digits = 1)),
    colour = myred, alpha = 0.7, nudge_y = -4) +
  ggtitle("Proportion of included blocks",
          subtitle=str_c("Group size = ", slot_chunk_res, " slots")) +
  xlab("Epoch") +
  ylab("Percent proposed and included") +
  ylim(0, 100)
```

## Correctness of attestations

### Target checkpoint

Attestations vouch for some target checkpoint to justify. We can check whether they vouched for the correct one by comparing their `target_block_root` with the latest known block root as of the start of the attestation epoch (that's a mouthful). How many individual attestations correctly attest for the target?

```{r}
n_individual_ats <- stats_per_slot %>%
  pull(included_ats) %>%
  sum()
n_correct_target_ats <- stats_per_slot %>%
  pull(correct_targets) %>%
  sum()

tibble(
  Name = c("Individual attestations", "Correct target attestations", "Percent correct"),
  Value = c(n_individual_ats, n_correct_target_ats, round(n_correct_target_ats / n_individual_ats * 100, digits = 2)
  )
) %>%
  paged_table()
```

How does the correctness evolve over time?

```{r}
stats_per_slot %>%
  .[, slot_chunk:=att_slot %/% slot_chunk_res] %>%
  .[, .(percent_correct_target=sum(correct_targets) / sum(included_ats) * 100), by=slot_chunk] %>%
  ggplot() +
  geom_line(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_target),
            colour = mygreen) +
  geom_point(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_target),
             colour = mygreen) +
  geom_text(aes(
    x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_target,
    label = round(percent_correct_target, digits = 1)),
    colour = mygreen, alpha = 0.7, nudge_y = -4) +
  ggtitle("Correct targets in included attestations",
          subtitle=str_c("Group size = ", slot_chunk_res, " slots")) +
  xlab("Epoch") +
  ylab("Percent correct targets") +
  ylim(0, 100)
```

### Head of the chain

Attestations must also vote for the correct head of the chain, as returned by the [GHOST fork choice rule]. To check for correctness, one looks at the latest block known as of the attestation slot. Possibly, this block was proposed for the same slot as the attestation `att_slot`. When the `beacon_block_root` attribute of the attestation and the latest block root match, the head is correct!

```{r}
n_correct_head_ats <- stats_per_slot %>%
  pull(correct_heads) %>%
  sum()

tibble(
  Name = c("Individual attestations", "Correct head attestations", "Percent correct"),
  Value = c(n_individual_ats, n_correct_head_ats, round(n_correct_head_ats / n_individual_ats * 100, digits = 2)
  )
) %>%
  paged_table()
```

How does the correctness evolve over time?

```{r}
stats_per_slot %>%
  .[, slot_chunk:=att_slot %/% slot_chunk_res] %>%
  .[, .(percent_correct_head=sum(correct_heads) / sum(included_ats) * 100), by=slot_chunk] %>%
  ggplot() +
  geom_line(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_head),
            colour = "purple") +
  geom_point(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_head),
             colour = "purple") +
  geom_text(aes(
    x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_head,
    label = round(percent_correct_head, digits = 1)),
    colour = "purple", alpha = 0.7, nudge_y = -4) +
  ggtitle("Correct heads in included attestations",
          subtitle=str_c("Samples = ", until_slot, " slots; group size = ", slot_chunk_res, " slots.")) +
  xlab("Epoch") +
  ylab("Percent correct head") +
  ylim(0, 100)
```

## Aggregate attestations

eth2 is built to scale to tens of thousands of validators. This introduces overhead from message passing (and inclusion) when these validators are asked to vote on the canonical chain. To alleviate the beacon chain, votes (a.k.a. **individual attestations**) can be **aggregated**.

In particular, an attestation contains five attributes:

- The slot it is attesting for ("**attestation slot**").
- The index of its committee in the slot ("**attestation committee**").
- Its vote for the head of the beacon chain, given by the fork choice rule.
- Its vote for the source, i.e., the last justified checkpoint in its view.
- Its vote for the target, i.e., the checkpoint to be justified in its view.

Since we expect validators to broadly agree in times of low latency, we also expect that a lot of individual attestations will share these same five attributes. We can aggregate such a set of individual attestations $I$ into a single, aggregate, attestation.

<aside>
Aggregators are randomly selected by the beacon chain, whose job it is to collect such individual attestations and package them in aggregates.
</aside>

When we have $N$ active validators, about $N / 32$ are selected to attest for each slot in an epoch. The validators for a slot $s$ are further divided between a few committees. Identical votes from validators in the same committee can be aggregated. Assume that two aggregate attestations were formed from individual attestations of validators in set $C(s, c)$, validators in committee $c$ attesting for slot $s$. One aggregate contains individual attestations from set $I \subseteq C(s, c)$ and the other individual attestations from set $J \subseteq C(s, c)$. We have two cases:

- When the intersection of $I$ and $J$ is non-empty, we cannot aggregate the two aggregates further.
- When the intersection of $I$ and $J$ is empty, the two aggregates can themselves be aggregated, into one containing attestations from validator set $I \cup J$.

### How many individual attestations are contained in aggregates?

```{r message=FALSE}
all_ats[, contained_ats:=str_count(attesting_indices, "1")]

all_ats %>%
  .[, .(count=.N), by=contained_ats] %>%
  ggplot() +
  geom_col(aes(x = contained_ats, y = count), fill=myred) +
  ggtitle("Number of individual attestations per aggregate (histogram)",
          subtitle = str_c("Aggregate attestations = ", nrow(all_ats))) +
  xlab("Number of attestations in aggregate") +
  ylab("Count")
```

We can plot the same, weighing by the size of the validator set in the aggregate, to count how many individual attestations each size of aggregates included.

```{r}
all_ats %>%
  .[, .(count=.N * contained_ats), by=contained_ats] %>%
  ggplot() +
  geom_col(aes(x = contained_ats, y = count), fill=myred) +
  ggtitle("Number of individual attestations per aggregate (histogram, weighted)",
          subtitle = str_c("Aggregate attestations = ", nrow(all_ats))) +
  xlab("Number of attestations in aggregate") +
  ylab("Number of individual attestations")
```

Overall, we can plot the [Lorenz curve](https://en.wikipedia.org/wiki/Lorenz_curve) of aggregate attestations. This allows us to find out the share of attestations held by the 20% largest aggregates.

```{r}
L <- Lc(all_ats$contained_ats)
```

```{r}
L_tibble <- tibble(p = L$p, L = L$L) %>%
  filter(row_number() %% 100000 == 1 | row_number() == max(row_number()))

L_80q <- quantile(L$L, 0.8, names=FALSE) %>%
  round(digits = 2)

L_tibble %>%
  ggplot() +
  geom_line(aes(x = p, y = L), colour = myred, size = 1.1) +
  geom_abline(slope = 1, intercept = 0, linetype="dotted") +
  geom_vline(xintercept = 0.8, colour = "steelblue", linetype = "dotted", size = 1.1) +
  geom_hline(yintercept = L_80q, colour = "steelblue", size = 1.1) +
  scale_x_continuous(
    breaks = sort(c(c(0.8), with(L_tibble, pretty(range(p))))),
  ) +
  scale_y_continuous(
    breaks = sort(c(c(L_80q), with(L_tibble, pretty(range(p))))),
  ) +
  ggtitle("Lorenz curve of aggregate attestation sizes",
          subtitle = str_c("Aggregate attestations = ", nrow(all_ats))) +
  xlab("Aggregation percentile") +
  ylab("Cumulative share of attestations")
```

The answer is `r (100 - L_80q * 100)`%.

#### How much savings did aggregates provide?

We compare how many individual attestations exist to how many aggregates were included in blocks.

```{r}
n_aggregates <- all_ats %>% nrow()
savings_ratio <- round(n_individual_ats / n_aggregates, digits=2)

tibble(Name = c("Individual attestations", "Included aggregates", "Savings ratio"),
       Value = c(n_individual_ats, n_aggregates,
                 savings_ratio)) %>%
  paged_table()
```

We have `r round(n_individual_ats / n_aggregates, digits = 2)` times more individual attestations than aggregates, meaning that if we were not aggregating, we would have `r round(n_individual_ats / n_aggregates, digits = 2)` as much data on-chain.

### In how many aggregate attestations is a single attestation included?

We look at all _individual_ attestations in our dataset, i.e., individual, unaggregated votes, and measure how many times they were included in an aggregate.

```{r}
appearances_in_aggs %>%
  ggplot() +
  geom_col(aes(x = appearances, y = count), fill=myred) +
  scale_y_log10() +
  ggtitle("Number of times an individual attestation is included in an aggregate (histogram)",
          subtitle = str_c("Individual attestations = ", n_individual_ats)) +
  xlab("Number of inclusions") +
  ylab("Count (log10)")
```

Most attestations were included in an aggregate once only

### How many redundant aggregate attestations are there?

We call **myopic redundant** identical aggregate attestations (same five attributes and same set of validator indices) which are included in more than one block. It can happen when a block producer does not see that an aggregate was previously included (e.g., because of latency), or simply when the block producer doesn't pay attention and greedily adds as many aggregates as they know about.

```{r}
myopic_redundant_ats %>%
  ggplot() +
  geom_col(aes(x = appearances, y = count), fill=myred) +
  ggtitle("Number of times one aggregate attestation is included (histogram)",
          subtitle = str_c("Aggregate attestations = ", nrow(all_ats))) +
  xlab("Number of times redundant") +
  ylab("Count (log10)") +
  scale_y_log10()
```

The mode is 1, which is also the optimal case. A redundant aggregate does not have much purpose apart from bloating the chain.

We could generalise this definition and call **redundant** an aggregate included in a block for which all of its attesting indices were previously seen in other aggregates. We didn't compute these as they are much harder to count.

### How many times did a block include the exact same aggregate attestation more than once?

We could call these **strongly redundant**, as this is pure waste.

```{r}
n_strong_redundant_twice <- strong_redundant_ats %>%
  pull(count) %>%
  pluck(2)
n_strong_redundant_over_twice <- strong_redundant_ats %>%
  pull(count) %>%
  sum() - n_strong_redundant_twice - strong_redundant_ats %>% pull(count) %>% pluck(1)
strong_redundant_ats %>%
  paged_table()
```

We see that `r n_strong_redundant_twice` times, identical aggregates were included twice in the same block.

### How many aggregates in a block are included by another aggregate in the same block?

We now define **subset aggregates**. Suppose two aggregates in the same block with equal attributes (slot, committee index, beacon root, source root and target root) include validator sets $I$ and $J$ respectively. If we have $I \subset J$, i.e., if all validators of the first aggregate are also included in the second aggregate (but the reverse is not true), then we call the first aggregate a **subset aggregate** of the second.

Subset aggregates, much like redundant aggregate attestations (equal aggregates included in more than one block of the canonical chain), can be removed from the finalised chain without losing any voting information. In fact, subset aggregates use much less local information than redundant aggregates. To root out subset aggregates, a client simply must ensure that no aggregate it is prepared to include in a block is a subset aggregate of another. Meanwhile, to root out redundant aggregates, a client must check all past blocks (until the inclusion limit of 32 slots) to ensure that it is not including a redundant aggregate. In a sense, subset aggregate are "worse" as they should be easier to root out.

```{r}
subset_until_slot <- 15000
```

So among all included aggregates in blocks, how many are subset aggregates? We count these instances for attestations included in blocks until slot `r subset_until_slot`.

<aside>
If we need to produce more heat, we may extend to more slots.
</aside>

```{r}
n_aggregates_until <- all_ats[slot < subset_until_slot] %>%
  nrow()

n_subset_ats <- sum(subset_ats$n_subset)
percent_subset <- round(n_subset_ats / n_aggregates_until, digits=4) * 100
tibble(Name = c("Subset aggregates", "Included aggregates", "Percentage of subset aggregates"),
       Value = c(n_subset_ats, n_aggregates_until,
                 percent_subset)) %>%
  paged_table()
```

We find that `r percent_subset`% included aggregates are subset aggregates.

#### How often are subset aggregates of size 1?

Taking a look at instances of subset aggregates, we often observe that the subset aggregate has size 1. In other words, it is often the case that a "big" aggregate is included, aggregating very many validators, and then a second aggregate of size 1, namely, an individual attestation, is included too, while this second individual attestation is already aggregated by the first, larger aggregate.

```{r}
n_subset_ind_ats <- sum(subset_ats$n_subset_ind)
percent_subset_ind <- round(n_subset_ind_ats / n_subset_ats, digits=4) * 100
tibble(Name = c("Subset aggregates of size 1", "Subset aggregates",
                "Percentage of subset aggregates of size 1"),
       Value = c(n_subset_ind_ats, n_subset_ats,
                 percent_subset_ind)) %>%
  paged_table()
```

Awesome!! Clients are leaving subset aggregates of size 1 out of their blocks. This is the right decision.

### How many times were clashing attestations included in blocks?

We look at situations where two aggregate attestations are included in the same block, with identical attributes (same attesting slot, attesting committee, beacon chain head, source block and target block) but different attesting indices and neither one is a subset of the other. We define the following two notions, assuming the two aggregate attestations include attestations of validator sets $I$ and $J$ respectively:

- **Strongly clashing:** The two aggregates share some validator indices, i.e., $I \cap J \neq \emptyset$. The two aggregate attestations were incompatible, so could not be aggregated further.
- **Weakly clashing:** The two aggregates have different validator indices, i.e., $I \cap J = \emptyset$. The two aggregate attestations could have been aggregated further.

Let's first count how many aggregates are strongly clashing in blocks before slot `r subset_until_slot`.

```{r}
n_strongly_clashing <- sum(subset_ats$n_strongly_clashing)
percent_strongly_clashing <- round(n_strongly_clashing / n_aggregates_until, digits=4) * 100
tibble(Name = c("Strongly clashing aggregates", "Included aggregates", "Percentage of strongly clashing"),
       Value = c(n_strongly_clashing, n_aggregates_until,
                 percent_strongly_clashing)) %>%
  paged_table()
```

How many are weakly clashing?

```{r}
n_weakly_clashing <- sum(subset_ats$n_weakly_clashing)
percent_weakly_clashing <- round(n_weakly_clashing / n_aggregates_until, digits=4) * 100
tibble(Name = c("Weakly clashing aggregates", "Included aggregates", "Percentage of weakly clashing"),
       Value = c(n_weakly_clashing, n_aggregates_until,
                 percent_weakly_clashing)) %>%
  paged_table()
```

None! That's pretty great. It means blocks always include the most aggregated possible attestations, and we have a local optimum to the aggregation problem.

Note that optimally aggregating a set of aggregates is NP-complete! Here is a reduction of the optimal aggregation problem to the [graph colouring](https://en.wikipedia.org/wiki/Graph_coloring). Set aggregate attestations as vertices in a graph, with an edge drawn between two vertices if the validator sets of the two aggregates have a non-empty overlap. In the graph colouring, we look for the minimum number of colours necessary to assign a colour to each vertex such that two connected vertices do not have the same colour. All vertices who share the same colour have an empty overlap, and thus can be combined into an aggregate. The minimum number of colours necessary to colour the graph tells us how few aggregates were necessary to combine a given set of aggregates further.

### Aggregates glossary

```{r}
n_size_1_ags <- all_ats %>%
  .[, .(count=.N), by=contained_ats] %>%
  pull(count) %>%
  pluck(1)
n_myopic_redundant <- readRDS(here::here("rds_data/redundant_ats.rds")) %>%
  filter(appearances > 1) %>%
  pull(count) %>%
  sum()
percent_myopic_redundant <- round(n_myopic_redundant / n_aggregates, digits=4) * 100
```

We've looked at aggregate attestations in a few different ways. We offer here a table to summarise the definitions we have introduced and associated statistics.

::: l-body-outset
| Name | Explanation | Statistics | Recommendation |
|-|-|-|-|
| Aggregate | Attestation summarising the vote of validators in a single committee | There are `r n_aggregates` aggregates included from slot 0 to slot `r until_slot` | x |
| Individual attestation | A single validator vote | There are `r n_individual_ats` individual attestations | x |
| Savings ratio | The ratio of individual attestations to aggregate attestations | The savings ratio is `r savings_ratio` | Keep it up! |
| Redundant aggregate | An aggregate containing validator attestations which were all already included on-chain, possibly across several aggregates with different attesting indices | x | Don't include these |
| Myopic redundant aggregate | An aggregate included more than once on-chain, always with the same attesting indices | There are `r n_myopic_redundant` myopic redundant aggregates, `r percent_myopic_redundant`% of all aggregates | These are redundant too: don't include them either |
:::

In the next table, we present definitions classifying aggregates when two or more instances are included _in the same block_ with the same five attributes (attesting slot and committee, beacon root, source root and target root).

::: l-body-outset
| Name | Explanation | Statistics | Recommendation |
|-|-|-|-|
| Strongly redundant aggregate | An aggregate included more than once _in the same block_ | There are `r n_strong_redundant_twice + n_strong_redundant_over_twice` strongly redundant aggregates | Keep only one of the strongly redundant aggregates |
| Subset aggregate | _If not strongly redundant_, an aggregate fully contained in another aggregate included _in the same block_ | There are `r n_subset_ats` subset aggregates until slot `r subset_until_slot`, `r percent_subset`% of all aggregates until slot `r subset_until_slot` | Drop all subset aggregates |
| Strongly clashing aggregates | _If not a subset aggregate_, an aggregate with attesting indices $I$ such that there exists another aggregate _attesting for the same in the same block_ with attesting indices $J$ and $I \cap J \neq \emptyset$ | There are `r n_strongly_clashing` strongly clashing aggregates until slot `r subset_until_slot`, `r percent_strongly_clashing`% of all aggregates until slot `r subset_until_slot` | These cannot be aggregated further. Do nothing |
| Weakly clashing aggregates | _If not a strongly clashing aggregate_, an aggregate with attesting indices $I$ such that there exists another aggregate _attesting for the same in the same block_ with attesting indices $J$ | There are `r n_weakly_clashing` weakly clashing aggregates until slot `r subset_until_slot`, `r percent_weakly_clashing`% of all aggregates until slot `r subset_until_slot` | These can be aggregated further into one aggregate with attesting indices $I \cup J$. In an ideal world, we have 0 weakly clashing aggregates |
:::

Size one aggregates do not appear often in the dataset, [an improvement compared to Medalla](https://ethereum.github.io/rig/medalla-data-challenge/notebooks/explore.html#aggregates-glossary).

::: l-body-outset
| Name | Explanation | Statistics | Recommendation |
|-|-|-|-|
| Subset aggregate of size 1 | A subset aggregate which is an unaggregated individual attestation | There are `r n_subset_ind_ats` subset aggregates of size 1 until slot `r subset_until_slot`, `r percent_subset_ind`% of all subset aggregates until slot `r subset_until_slot` | Definitely drop these |
| Aggregate of size 1 | An individual attestations included without being aggregated | There are `r n_size_1_ags` aggregates of size 1 | Either it is weakly clashing, so aggregate it further; or it is a subset aggregate, so drop it; or it is a redundant |
:::