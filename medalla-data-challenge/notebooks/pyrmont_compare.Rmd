---
title: "Pyrmont client comparison"
author:
- name: Barnab√© Monnot
  url: https://twitter.com/barnabemonnot
  affiliation: Robust Incentives Group, Ethereum Foundation
  affiliation_url: https://github.com/ethereum/rig
date: "`r Sys.Date()`"
output:
  distill::distill_article:
    toc: yes
    toc_depth: 3
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
description: |
  Onwards!
---

```{r setup, include=FALSE}
library(tidyverse)
library(data.table)
library(rmarkdown)
library(infer)

source(here::here("notebooks/lib.R"))

options(digits=10)
options(scipen = 999) 

# Make the plots a bit less pixellated
knitr::opts_chunk$set(dpi = 300)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

# A minimal theme I like
newtheme <- theme_grey() + theme(
  axis.text = element_text(size = 9),
  axis.title = element_text(size = 12),
  axis.line = element_line(colour = "#000000"),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_blank(),
  legend.title = element_text(size = 12),
  legend.text = element_text(size = 10),
  legend.box.background = element_blank(),
  legend.key = element_blank(),
  strip.text.x = element_text(size = 10),
  strip.background = element_rect(fill = "white")
)
theme_set(newtheme)

myred <- "#F05431"
myyellow <- "#FED152"
mygreen <- "#BFCE80"
client_colours <- c("#000011", "#ff9a02", "#eb4a9b", "#7dc19e")

end_epoch <- 1250
slots_per_epoch <- 32
until_slot <- (end_epoch + 2) * slots_per_epoch - 1
slot_chunk_res <- until_slot %/% 15
slots_per_year <- 365.25 * 24 * 60 * 60 / 12
epochs_per_year <- slots_per_year / slots_per_epoch
```

```{r cache=TRUE}
all_ats <- fread(here::here("pyrmont_data/all_ats.csv"))
all_bxs <- fread(here::here("pyrmont_data/all_bxs.csv"))
block_root_at_slot <- get_block_root_at_slot(all_bxs)
validators <- fread(here::here("pyrmont_data/initial_validators.csv"))
all_myopic_redundant_ats <- get_myopic_redundant_ats_detail(all_ats)
subset_ats <- fread(here::here("pyrmont_data/subset_ats.csv"))
val_series <- fread(here::here("pyrmont_data/val_series.csv"))
```

```{r}
# start_epoch <- 675
# end_epoch <- 900
# 
# start_balances <- get_balances_active_validators(start_epoch)[
#     validators[node_code > 0, .(validator_index, client, first_digit)], on="validator_index"
#   ] %>%
#   mutate(
#     measurement_epoch = start_epoch
#   ) %>%
#   select(-time_active, -activation_epoch)
# 
# end_balances <- get_balances_active_validators(end_epoch)[
#     validators[node_code > 0, .(validator_index, client, first_digit)], on="validator_index"
#   ] %>%
#   mutate(
#     measurement_epoch = end_epoch
#   ) %>%
#   select(-time_active, -activation_epoch)
# 
# reward_rates <- start_balances %>%
#   inner_join(end_balances,
#              by = c("validator_index", "client", "first_digit")) %>%
#   mutate(reward_rate = (balance.y - balance.x) / balance.x * 100 * epochs_per_year / (measurement_epoch.y - measurement_epoch.x))
```

```{r}
# Differences by client
# mean_diff <- reward_rates %>% 
#   filter(client == "lighthouse" | client == "prysm") %>%
#   specify(formula = reward_rate ~ client) %>% 
#   calculate(stat = "diff in means", order = c("lighthouse", "prysm"))
# 
# null_distribution <- reward_rates %>% 
#   filter(client == "lighthouse" | client == "prysm") %>%
#   specify(formula = reward_rate ~ client) %>% 
#   hypothesize(null = "independence") %>% 
#   generate(reps = 1000, type = "permute") %>% 
#   calculate(stat = "diff in means", order = c("lighthouse", "prysm"))
# 
# null_distribution %>% 
#   get_pvalue(obs_stat = mean_diff, direction = "both")
```

```{r}
# Differences by node region
# mean_diff <- reward_rates %>%
#   mutate(node_group = if_else(first_digit <= 2, "A", "B")) %>%
#   specify(formula = reward_rate ~ node_group) %>% 
#   calculate(stat = "diff in means", order = c("A", "B"))
# 
# null_distribution <- reward_rates %>%
#   mutate(node_group = if_else(first_digit <= 2, "A", "B")) %>%
#   specify(formula = reward_rate ~ node_group) %>% 
#   hypothesize(null = "independence") %>% 
#   generate(reps = 1000, type = "permute") %>% 
#   calculate(stat = "diff in means", order = c("A", "B"))
# 
# null_distribution %>% 
#   get_pvalue(obs_stat = mean_diff, direction = "both")
```

```{r}
# pairwise.t.test(reward_rates$reward_rate, reward_rates$client, p.adjust.method = "none")
```

```{r}
# reward_rates %>%
#   group_by(client) %>%
#   summarise(reward_rate = mean(reward_rate))
```

```{r}
# reward_rates %>%
#   mutate(node_group = if_else(first_digit <= 2, "A", "B")) %>%
#   group_by(node_group) %>%
#   summarise(reward_rate = mean(reward_rate))
```

```{r}
# pairwise.t.test(reward_rates$reward_rate, reward_rates$first_digit, p.adjust.method = "none")
```

```{r message=FALSE}
get_reward_timelines <- function(start_epoch, end_epoch, step=25) {
  start_balances <- get_balances_active_validators(start_epoch)[
    validators[node_code > 0, .(validator_index, client, first_digit)], on="validator_index"
  ] %>%
    mutate(
      measurement_epoch = start_epoch
    ) %>%
    select(-time_active, -activation_epoch)
  
  seq(start_epoch+step, end_epoch+1, step) %>%
    map(function(epoch) {
      end_balances <- get_balances_active_validators(epoch)[
        validators[node_code > 0, .(validator_index, client, first_digit)], on="validator_index"
      ] %>%
        mutate(
          measurement_epoch = epoch
        ) %>%
        select(-time_active, -activation_epoch)
      
      t <- start_balances %>%
        inner_join(end_balances,
                   by = c("validator_index", "client", "first_digit")) %>%
        mutate(reward_rate = (balance.y - balance.x) / balance.x * 100 * epochs_per_year / (measurement_epoch.y - measurement_epoch.x))
      rr <- t %>%
        group_by(group = client, measurement_epoch.y) %>%
        summarise(avg_rr = mean(reward_rate), n_group = n()) %>%
        mutate(name = "client") %>%
        union(
          t %>%
            group_by(group = as.character(first_digit), measurement_epoch.y) %>%
            summarise(avg_rr = mean(reward_rate), n_group = n()) %>%
            mutate(name = "region")
        )
      
      start_balances <- end_balances
      return(rr)
    }) %>%
    bind_rows()
}
```

## Client distribution

We have roughly equal distribution of clients in the network at genesis.

```{r}
validators %>%
  .[, .(count=.N), by=client] %>%
  ggplot() +
  geom_col(aes(x = client, y = count), fill = myred) +
  ggtitle("Distribution of clients in the dataset") +
  xlab("Declared client") +
  ylab("Count")
```

```{r}
get_grid_per_client <- function(val_series, selected_client) {
  val_series[client == selected_client] %>%
    mutate(validator_index = as.factor(validator_index)) %>%
    ggplot() +
    geom_tile(aes(x = epoch, y = validator_index, fill = included_ats)) +
    scale_fill_gradient(low = myred, high = mygreen, na.value = NA,
                        limits = c(0, max(val_series$expected_ats)),
                        guide = FALSE) +
    scale_x_continuous(expand = c(0, 0)) +
    xlab("Epoch") +
    ylab("Validators") +
    theme(axis.text.y=element_blank(),
          axis.ticks.y=element_blank(),
          panel.background=element_rect(fill=myred, colour=myred),
          axis.title.x = element_text(size = 6),
          axis.title.y = element_text(size = 6),
          axis.text.x = element_text(size = 6),
          strip.text = element_text(size = 7))
}

plot_grid <- function(start_epoch, end_epoch, committees = NULL) {
  l <- c("prysm", "lighthouse", "nimbus", "teku") %>%
    map(function(client) {
      get_grid_per_client(val_series, client)
    })
  
  l[["prysm"]] | l[["lighthouse"]] | l[["nimbus"]] | l[["teku"]]
}
```

## Attestations over time

In the plots below, we align on the y-axis validators activated at genesis. A point on the plot is coloured in green when the validator has managed to get their attestation included for the epoch given on the x-axis. Otherwise, the point is coloured in red. Note that we do not check for the correctness of the attestation, merely its presence in some block of the beacon chain.

The plots allow us to check when a particular client is experiencing issues, at which point some share of validators of that client will be unable to publish their attestations.

### Lighthouse

```{r, layout="l-screen", fig.height=2}
get_grid_per_client(val_series[
  validators[, .(validator_index, client)], on="validator_index"
], "lighthouse")
```

### Nimbus

```{r, layout="l-screen", fig.height=2}
get_grid_per_client(val_series[
  validators[, .(validator_index, client)], on="validator_index"
], "nimbus")
```

### Prysm

```{r, layout="l-screen", fig.height=2}
get_grid_per_client(val_series[
  validators[, .(validator_index, client)], on="validator_index"
], "prysm")
```

### Teku

```{r, layout="l-screen", fig.height=2}
get_grid_per_client(val_series[
  validators[, .(validator_index, client)], on="validator_index"
], "teku")
```

## Block-packing

A block can include at most 128 aggregate attestations. How many aggregate attestations did each client include on average?

```{r}
chunk_size <- 25
all_ats %>%
  .[, .(included_ats = .N), by=slot] %>%
  merge(all_bxs[, .(slot, proposer_index)]) %>%
  merge(validators[, .(validator_index, client)],
        by.x = c("proposer_index"), by.y = c("validator_index")) %>%
  mutate(epoch_chunk = slot %/% slots_per_epoch %/% chunk_size) %>%
  group_by(epoch_chunk, client) %>%
  summarise(included_ats = mean(included_ats)) %>%
  ggplot(aes(x = epoch_chunk * chunk_size, y = included_ats, group=client, color=client)) +
  geom_line() +
  scale_color_manual(name = "Client", values = client_colours) +
  ylim(0, 128) +
  ggtitle("Average number of aggregates included per block") +
  xlab("Declared client") +
  ylab("Average number of aggregates")
```

Smaller blocks lead to healthier network, as long as they do not leave attestations aside. We check how each client manages redundancy in the next sections.

### Myopic redundant aggregates

Myopic redundant aggregates were already published, with the same attesting indices, in a previous block.

```{r}
chunk_size <- 25
all_bxs %>%
  merge(validators[, .(validator_index, client)],
        by.x = c("proposer_index"), by.y = c("validator_index")) %>%
  merge(all_myopic_redundant_ats, by.x = c("slot"), by.y = c("slot"), all.x = TRUE) %>%
  setnafill("const", fill = 0, cols = c("n_myopic_redundant")) %>%
  mutate(epoch_chunk = slot %/% slots_per_epoch %/% chunk_size) %>%
  group_by(epoch_chunk, client) %>%
  summarise(n_myopic_redundant = mean(n_myopic_redundant)) %>%
  ggplot(aes(x = epoch_chunk * chunk_size, y = n_myopic_redundant, group=client, color=client)) +
  geom_line() +
  scale_color_manual(name = "Client", values = client_colours) +
  ggtitle("Average number of myopic redundant aggregates per block") +
  xlab("Epoch") +
  ylab("Average myopic aggregates")
```

### Subset aggregates

```{r}
subset_until_slot <- 15000
```

Subset aggregates are aggregates included in a block which are fully covered by another aggregate included in the same block. Namely, when aggregate 1 has attesting indices $I$ and aggregate 2 has attesting indices $J$, aggregate 1 is a subset aggregate when $I \subset J$.

<aside>
This analysis is carried until slot `r subset_until_slot`.
</aside>

```{r}
chunk_size <- 10
all_bxs[slot <= subset_until_slot] %>%
  merge(validators[, .(validator_index, client)],
        by.x = c("proposer_index"), by.y = c("validator_index")) %>%
  merge(subset_ats, by.x = c("slot"), by.y = c("slot"), all.x = TRUE) %>%
  setnafill("const", fill = 0, cols = c("n_subset", "n_subset_ind", "n_weakly_clashing", "n_strongly_clashing")) %>%
  mutate(epoch_chunk = slot %/% slots_per_epoch %/% chunk_size) %>%
  group_by(epoch_chunk, client) %>%
  summarise(n_subset = mean(n_subset)) %>%
  ggplot(aes(x = epoch_chunk * chunk_size, y = n_subset, group=client, color=client)) +
  geom_line() +
  scale_color_manual(name = "Client", values = client_colours) +
  ggtitle("Average number of subset aggregates per block") +
  xlab("Epoch") +
  ylab("Average subset aggregates")
```

Lighthouse and Nimbus both score a perfect 0.

```{r}
chunk_size <- 5
all_ats[slot <= subset_until_slot] %>%
  .[, .(included_ats = .N), by=slot] %>%
  merge(all_bxs[, .(slot, proposer_index)]) %>%
  merge(validators[, .(validator_index, client)],
        by.x = c("proposer_index"), by.y = c("validator_index")) %>%
  merge(subset_ats, by.x = c("slot"), by.y = c("slot"), all.x = TRUE) %>%
  setnafill("const", fill = 0, cols = c("n_subset", "n_subset_ind", "n_weakly_clashing", "n_strongly_clashing")) %>%
  mutate(epoch_chunk = slot %/% slots_per_epoch %/% chunk_size) %>%
  group_by(epoch_chunk, client) %>%
  summarise(n_subset = mean(n_subset)) %>%
  ggplot(aes(x = epoch_chunk * chunk_size, y = n_subset, group=client, color=client)) +
  geom_line() +
  scale_color_manual(name = "Client", values = client_colours) +
  ggtitle("Percentage of subset aggregates among included aggregates") +
  xlab("Epoch") +
  ylab("Percentage of subset aggregates in block")
```

## Reward rates since genesis

```{r cache=TRUE, message=FALSE}
rr_series <- get_reward_timelines(1, end_epoch + 1, step=50)
```

We first look at the reward rates per client since genesis.

```{r}
rr_series %>%
  filter(name == "client") %>%
  ggplot(aes(x = measurement_epoch.y, y = avg_rr, group=group, color=group)) +
  geom_line() +
  scale_color_manual(name = "Client", values = client_colours) +
  xlab("Epoch") +
  ylab("Average reward rate") +
  ggtitle("Timeline of average rates of reward per client")
```

Clients are hosted on AWS nodes scattered across four regions in roughly equal proportions. We look at the reward rates per region.

```{r}
rr_series %>%
  filter(name == "region") %>%
  ggplot(aes(x = measurement_epoch.y, y = avg_rr, group=group, color=group)) +
  geom_line() +
  xlab("Epoch") +
  ylab("Average reward rate") +
  ggtitle("Timeline of average rates of reward per region") +
  scale_color_discrete(name = "Region")
```

Performing an omnibus test to detect significant difference between any of the four groups, we are unable to find such significance.

## Experiment: Scaling down nodes

Around epoch 1020, nodes from regions 1 and 2 were scaled down from t3.xlarge units (4cpu 16GB mem, with unlimited cpu burst) to m5.large units (2cpu, 8GB mem, no burst). We observe a significant loss of performance despite continuous uptime.

```{r cache=TRUE, message=FALSE}
rr_series <- get_reward_timelines(900, end_epoch, step=10)
```

```{r}
rr_series %>%
  filter(name == "region") %>%
  ggplot(aes(x = measurement_epoch.y, y = avg_rr, group=group, color=group)) +
  geom_line() +
  xlab("Epoch") +
  ylab("Average reward rate") +
  ggtitle("Timeline of average rates of reward per region") +
  scale_color_discrete(name = "Region")
```

Reward rates per client are affected in roughly equal proportions.

```{r}
rr_series %>%
  filter(name == "client") %>%
  ggplot(aes(x = measurement_epoch.y, y = avg_rr, group=group, color=group)) +
  geom_line() +
  scale_color_manual(name = "Client", values = client_colours) +
  xlab("Epoch") +
  ylab("Average reward rate") +
  ggtitle("Timeline of average rates of reward per client")
```

### Analysis by duty

```{r}
start_epoch <- 900
chunk_size <- 10
```

We look at four metrics across each region:

- Percentage of included attestations.
- Percentage of correct targets among expected attestations.
- Percentage of correct heads among expected attestations.
- Average inclusion delay.

To obtain a time series, we divide the period between epoch `r start_epoch` and epoch `r end_epoch` in chunks of size `r chunk_size` epochs. For each validator, we record how many included attestations appear in the dataset (ranging between 0 and `r chunk_size` for each chunk), the number of correct targets, correct heads and its average inclusion delay. We average over all validators in the EF-controlled set, measuring metrics either per client or per region.

We start by looking at the metrics per region.

```{r, layout="l-screen", fig.height=2}
val_series[
  validators[node_code > 0, .(validator_index, client, region=as.character(first_digit))], on="validator_index"
][epoch >= start_epoch,][
  , .(
    included_ats=sum(included_ats)/sum(expected_ats) * 100,
    correct_targets=sum(correct_targets)/sum(expected_ats) * 100,
    correct_heads=sum(correct_heads)/sum(expected_ats) * 100,
    inclusion_delay=mean(inclusion_delay, na.rm = TRUE)
  ),
  by=.(epoch, region)
] %>%
  melt(id.vars = c("epoch", "region")) %>%
  ggplot() +
  geom_line(aes(x = epoch, y = value, group=region, color=region)) +
  xlab("Epoch") +
  ylab("Value") +
  scale_color_discrete(name = "Region") +
  facet_wrap(vars(variable), nrow=1, scales="free_y") +
  theme(axis.title.x = element_text(size = 6),
        axis.title.y = element_text(size = 6),
        axis.text.x = element_text(size = 6),
        axis.text.y = element_text(size = 6),
        strip.text = element_text(size = 4),
        legend.title = element_text(size = 6),
        legend.text = element_text(size = 6))
```

And now per client.

```{r, layout="l-screen", fig.height=2}
val_series[
  validators[node_code > 0, .(validator_index, client, first_digit)], on="validator_index"
][epoch >= start_epoch,][
  , .(
    included_ats=sum(included_ats)/sum(expected_ats) * 100,
    correct_targets=sum(correct_targets)/sum(expected_ats) * 100,
    correct_heads=sum(correct_heads)/sum(expected_ats) * 100,
    inclusion_delay=mean(inclusion_delay, na.rm = TRUE)
  ),
  by=.(epoch, client)
] %>%
  melt(id.vars = c("epoch", "client")) %>%
  ggplot() +
  geom_line(aes(x = epoch, y = value, group=client, color=client)) +
  xlab("Epoch") +
  ylab("Value") +
  scale_color_manual(name = "Client", values = client_colours) +
  facet_wrap(vars(variable), nrow=1, scales="free_y") +
  theme(axis.title.x = element_text(size = 6),
        axis.title.y = element_text(size = 6),
        axis.text.x = element_text(size = 6),
        axis.text.y = element_text(size = 6),
        strip.text = element_text(size = 4),
        legend.title = element_text(size = 6),
        legend.text = element_text(size = 6))
```

